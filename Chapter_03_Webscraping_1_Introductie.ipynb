{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfe6ed68-eca1-46d7-9665-3a5f86f5d3a5",
   "metadata": {},
   "source": [
    "# Webscraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28892af-56c3-44a1-8cf0-251af2439acb",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "Dit notebook laat manieren zien hoe webpaginas te manipuleren zijn en hoe de data ervan te _scrapen_ is. \n",
    "\n",
    "> \"_Scrapen is een computertechniek waarbij software wordt gebruikt om informatie van webpagina's te extraheren en al dan niet te analyseren._\"  <sub>[wiki]<sub>\n",
    "\n",
    "In feite maak je contact via Python om informatie op te halen van een externe informatiebron zoals een website of api om daar gegevens vandaan te halen. Deze gegevens worden vervolgens in de eigen omgeving opgeslagen. \n",
    "    \n",
    "### Libraries\n",
    "Python heeft een aantal [internet] tools die daarbij helpen.  \n",
    "De meest gebruike zijn [urllib.request] en [html.parser].  \n",
    "Deze libraries hebben een _low-level_ design waardoor het te customizen is.  \n",
    "Hierdoor moet er een hoop code schrijven om de functies zo te maken dat het doel wordt bereikt.  \n",
    "Gelukkig zijn er third-party libraries die een _high-level_ interface bieden.  \n",
    "Python heeft ook de [json] module om objecten te encoden naar json en inkomende json te decoden.  \n",
    "\n",
    "Er zijn veel Third-party libraries de gebruikt kunnen worden om data van het web te halen.  \n",
    "Hieronder een kleine selectie waarvan we een paar in dit notebook gaat gebruiken.  \n",
    "\n",
    "[requests] is de _high-level_ interface om [HTTP request methods] te versturen naar API's of websites.\n",
    "\n",
    "[beautifulsoup4] wordt gebruikt om HTML of XML te parsen.  \n",
    "\n",
    "[selenium], de meest bekende web-automation tool welk ook veel gebruikt wordt om websites te testen.  \n",
    "\n",
    "[scrapy] een web-crawler framework voor Python met een hoop features.\n",
    "\n",
    "[httpx] de _next-generation_ HTTP client voor Python.  \n",
    "Als je bekend ben met [requests] dan is de overstap naar [httpx] klein.  \n",
    "Ondersteunt HTTP2 en de Python [async] functionaliteit waar [requests] dit niet ondersteunt.\n",
    "\n",
    "\n",
    "    \n",
    "[internet]: https://docs.python.org/3/library/internet.html \"Internet Protocols and Support\"\n",
    "[urllib.request]: https://docs.python.org/3/library/urllib.request.html \"Extensible library for opening URLs\"\n",
    "[json]: https://docs.python.org/3/library/json.html \"JSON encoder and decoder\"\n",
    "[html.parser]: https://docs.python.org/3/library/html.parser.html \"Simple HTML and XHTML parser\"\n",
    "\n",
    "[httpx]: https://www.python-httpx.org/ \"A next-generation HTTP client for Python\"\n",
    "[scrapy]: https://scrapy.org/ \"Web Crawling Framework\"\n",
    "[selenium]: https://www.selenium.dev/documentation/en/ \"selenium\"\n",
    "[beautifulsoup4]: https://beautiful-soup-4.readthedocs.io/en/latest/ \"Beautiful Soup\"\n",
    "[requests]: https://docs.python-requests.org/en/master/index.html \"Requests: HTTP for Humans\"\n",
    "\n",
    "[wiki]: https://nl.wikipedia.org/wiki/Scrapen\n",
    "[HTTP request methods]: https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods \"HTTP request methods\"\n",
    "[async]: https://docs.python.org/3/library/asyncio.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dc1348",
   "metadata": {},
   "source": [
    "## Developer tools\n",
    "\n",
    "Naast Python gaan we ook werken met de [Developer tools] van de web browser.  \n",
    "[Chrome] en [Firefox] hebben dat beiden in hun browser.  \n",
    "De knop `F12` of de sneltoetsen `Shift` + `Control` + `I` opent de developer tools van de browser.  \n",
    "    \n",
    "\n",
    "\n",
    "[Developer tools]: https://en.wikipedia.org/wiki/Web_development_tools\n",
    "[Chrome]: https://developer.chrome.com/docs/devtools/open/ \"Chrome Developer tools\"\n",
    "[Firefox]: https://developer.mozilla.org/en-US/docs/Learn/Common_questions/What_are_browser_developer_tools \"Firefox Developer tools\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac54e4a9-6616-4816-b579-28d1c0b3d9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ""
     ]
    }
   ],
   "source": [
    "# install the packages\n",
    "!python -m pip install --upgrade pip requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f019bce-e422-4e50-bd65-a7c3384a520d",
   "metadata": {},
   "source": [
    "## Scrapen van een API\n",
    "\n",
    "Het makelijkste om data op te vragen is doormiddel van een API. Veel websites hebben geen openbare API.\n",
    "\n",
    "Toch kan het zo zijn dat de website een API gebruikt om data van de client naar de server te sturen.\n",
    "Zo kan de website dynamisch _(zonder te refreshen)_ de data op de pagina vernieuwen.   \n",
    "Hier wordt [XMLHTTPRequests (XHR)] voor gebruikt.\n",
    "\n",
    "In de Developer Tools onder de tab Network zie je het dataverkeer en de daarbij horende HTTP request methods.  \n",
    "Om goed te zien wat een website krijgt en verstuurd moet de optie Preserve log/ Persist Logs en de Disable Cache aan staan.  \n",
    "Met deze opties aan behoudt de network tab alle logs en vraagt de website alle data op die anders werd onthouden in de Cache.  \n",
    "\n",
    "---\n",
    "\n",
    "https://www.demoblaze.com/ een demo website van [Blazemeter] en gebruikt XHR.  \n",
    "In de notebook cells hieronder open we de demo website en bekijken we de Network tab voor XHR berichtenverkeer.  \n",
    "En gaan we [requests] gebruiken om data van de webpagina op te vragen.  \n",
    "\n",
    "[XMLHTTPRequests (XHR)]: https://nl.wikipedia.org/wiki/XMLHTTP\n",
    "[Blazemeter]: https://www.blazemeter.com/\n",
    "[requests]: https://docs.python-requests.org/en/master/index.html \"Requests: HTTP for Humans\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacc5291-7deb-4e48-8e88-4bc8388367b2",
   "metadata": {},
   "source": [
    "## Oefening met developer tools\n",
    "Open een browser en de developer tools.  \n",
    "Zet de opties Preserve logs, Disable cache aan en filter op XHR  \n",
    "\n",
    "> ![Developer tools](./img/devtools_XHR_filter.png \"Preserve logs, Disable cache, filter XHR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb0abcb-487a-4914-bbde-0540aabeafb6",
   "metadata": {},
   "source": [
    "Open de demo website, we zien dat er wat XHR type requests gedaan wordt.\n",
    "\n",
    "De url https://www.demoblaze.com/config.json wordt opgevraagt met de GET method.  \n",
    "\n",
    "> ![Developer tools XHR get](./img/devtools_XHR_get_request.png \"GET request, XHR type response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6de7a1b-d3d1-4e76-a998-e400f3b2ba64",
   "metadata": {},
   "source": [
    "Observeer de gegevens die te zien zijn in de response data. \n",
    "\n",
    "Als we er op klikken zien we de data die verstuurd en terug gekregen is.  \n",
    "Onder de tab Response krijgen we de _Raw response data_ te zien.  \n",
    "Dit kan van alles zijn, HTML, javascript en in dit geval JSON.  \n",
    "\n",
    "> ![Developer tools XHR response](./img/devtools_XHR_response.png \"raw response\")\n",
    "\n",
    "Hieronder wordt Python requests gebruikt om dezelfde data op te vragen.\n",
    "\n",
    "\n",
    "De syntax is als volgt: \n",
    "```\n",
    "responseObject = requests.get(url)\n",
    "```\n",
    "Nadat deze request url is uitgevoerd kun je bijvoorbeeld de pagina content ophalen via: \n",
    "```\n",
    "responseObject.content\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ac932df-180f-4cae-8177-8a24e1e465aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "base_url = 'https://www.demoblaze.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5fab87d-9910-4732-9fcd-ce01231c61b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\\n    \"API_URL\": \"https://api.demoblaze.com\",\\n    \"HLS_URL\": \"https://hls.demoblaze.com\"\\n}'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'config.json'\n",
    "url = urljoin(base_url, path)\n",
    "res = requests.get(url)\n",
    "\n",
    "# response content is de data terug gekregen van de GET request (Raw response data)\n",
    "res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e255cddb-43e3-4da4-96cc-9db229d0df74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'API_URL': 'https://api.demoblaze.com',\n",
       " 'HLS_URL': 'https://hls.demoblaze.com'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HLS is een streaming protocol\n",
    "# de API_URL hebben is nodig\n",
    "\n",
    "# er is JSON data ontvangen\n",
    "# de data kan geparsed worden door Python json module of door de Response.json() functie naar een dict.\n",
    "config_dict = res.json()\n",
    "config_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f388857-8142-4666-8f8b-d6be8fff7377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://api.demoblaze.com'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_url = config_dict.get('API_URL')\n",
    "api_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14ed447-5769-4766-b06b-b6ed4805a3e3",
   "metadata": {},
   "source": [
    "Op de demo website is er een lijst te zien met product catagories.  \n",
    "Wordt er op de Laptop catagorie geklikt dan wordt de Laptop catagorie opgrvraag van de server.  \n",
    "Dit gebeurt met een POST request naar de API url met het _bycat_ path.  \n",
    "Een POST request bevat meestal een payload of speciale headers, in dit geval is de payload een JSON string.  \n",
    "\n",
    "> ![Catagory request met payload](./img/devtools_post_request.png \"POST request met JSON payload\")\n",
    "\n",
    "In de tab Response zien we de data die verkregen is van de server.  \n",
    "Dit is wederom JSON data. \n",
    "\n",
    "Hieronder wordt Python requests gebruikt om dezelfde data op te vragen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dfc9a1d-5719-40bc-bff5-d07180263308",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'bycat'\n",
    "url = urljoin(api_url, path)\n",
    "\n",
    "payload = {'cat': 'notebook'}\n",
    "\n",
    "res = requests.post(url, json=payload)\n",
    "notebook_dict =  res.json()\n",
    "# dict structure: {'Items': [{'cat': 'notebook', id: <int>, 'img': <str>, 'price': <float>, 'title', <str>}, ... ]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87751a8e-a82e-485d-845c-d1005b9f81db",
   "metadata": {},
   "source": [
    "Nu de data is verkregen kan er overheen worden geitereerd.  \n",
    "De data kunnen we dan opslaan in een database, csv of Excel bestand.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51db0047-dfaa-468c-9b28-7c8b87956a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sony vaio i5         €790.0\n",
      "Sony vaio i7         €790.0\n",
      "MacBook air          €700.0\n",
      "Dell i7 8gb          €700.0\n",
      "2017 Dell 15.6 Inch  €700.0\n",
      "MacBook Pro          €1100.0\n"
     ]
    }
   ],
   "source": [
    "# loop over de items in de dict\n",
    "for item in notebook_dict['Items']:\n",
    "    if not item.get('cat') == 'notebook':  # skip de items die geen notebook zijn.\n",
    "        continue\n",
    "    title = item.get('title').strip()  # strip de whitespaces en newlines van de string.\n",
    "    price = item.get('price')\n",
    "    print(f'{title:20} €{price}')  # maak 'title' minstens 20 characters breed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648ca13a-ca6c-4f63-8d8a-431cfd2f62e4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Scrapen door de HTML te parsen\n",
    "\n",
    "HTML (HyperTextMarkupLanguage) is de opmaak van een webpagina.  \n",
    "De HTML kan dynamisch worden opgemaakt met (bijvoorbeeld) Javascipt code.  \n",
    "Maar HTML paginas kunnen ook statisch zijn.  \n",
    "Een statische pagina moet ververst worden om nieuwe data te zien.\n",
    "\n",
    "De server die de paginas naar de client stuurt moet wel weten wat het moet doen browser (client) een pagina opvraagt.  \n",
    "Als dit niet via JSON of speciale headers gebeurd dan wordt het commando beschreven in de URL zelf.  \n",
    "Dit gebeurd doormiddel van een _query_.  \n",
    "\n",
    "Een _query_ is de gedeelte in een URL na de `?`.  \n",
    "de query bestaat uit een _key_ en optioneel een _value_.  \n",
    "key en value worden aan elkaar gekoppeld doormiddel van een `=`.  \n",
    "Er kunnen ook meerdere queries in een url als de queries gesepereerd worden door een `&`.  \n",
    "De keys en values hoeven niet uniek te zijn.\n",
    "\n",
    "Voorbeeld van een valide URL:  \n",
    "`https://www.web.site/path.html?key=value&key=value&only_key`\n",
    "\n",
    "---\n",
    "\n",
    "https://computer-database.gatling.io/computers is een statische demo website van [Gatling] en gebruikt parameters in de URL.  \n",
    "In de notebook cells hieronder open we de demo website en bekijken we de Network tab voor XHR berichtenverkeer.  \n",
    "En gaan we [requests] gebruiken om data van de webpagina op te vragen.  \n",
    "We parsen de HTML met [beautifulsoup4].  \n",
    "\n",
    "[Gatling]: https://gatling.io\n",
    "[requests]: https://docs.python-requests.org/en/master/index.html \"Requests: HTTP for Humans\"\n",
    "[beautifulsoup4]: https://beautiful-soup-4.readthedocs.io/en/latest/ \"Beautiful Soup\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9e214e-c098-406d-9bf8-2bf106198c72",
   "metadata": {},
   "source": [
    "Open een browser en navigeer naar de demo pagina.  \n",
    "Open de developer tools.  \n",
    "Klik op de next knop op de demo pagina.\n",
    "In de developer tools open kan er worden gezien dat er een GET request is geweest.  \n",
    "De request en de URL in de browser hebben een query.  \n",
    "\n",
    "> ![query string params](./img/devtools_query_params.png \"Query String Parameters\")\n",
    "\n",
    "Met wat giswerk kan er worden bedacht wat de query bevat.\n",
    "\n",
    "`p=0` de key `p` en de value als cijfer moet waarschijnlijk de pagina voorstellen.  \n",
    "`n=10` de key `n` is hoogstwaarschijnlijk het aantal items in de [table] op de pagina.  \n",
    "`s=name` de [table] is gesorteerd op naam, dus `s` is voor _sort_.  \n",
    "`d=asc` moet dan voor de manier van sorteren zijn, `asc` staat voor _ascending_.\n",
    "\n",
    "[table]: https://developer.mozilla.org/en-US/docs/Learn/HTML/Tables/Basics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045e4abe-4eb6-47cb-bbb8-60336d63c8dd",
   "metadata": {},
   "source": [
    "Met deze kennis kunnen we een query maken voor een tabel met de benodigde regels.  \n",
    "De URL + query kan dan met Python-requests worden opgevraagd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d663bcf-84d5-4879-a89c-16697a8544ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urljoin\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab33f2c6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://computer-database.gatling.io/computers?p=0&n=5'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = 'https://computer-database.gatling.io/computers'\n",
    "query = '?p={page}&n={rows}'\n",
    "url = urljoin(base_url, query.format(page=0, rows=5))  # pagina 0, regels 5\n",
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dafc135-b64f-4137-8459-0f68e6259186",
   "metadata": {},
   "source": [
    "De URL is gecreeerd en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb4d4f4f-c8c2-42b0-a46b-39a3007e1a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86fbf20-2b29-451a-a917-430912e2d5fd",
   "metadata": {},
   "source": [
    "Het is niet nodig maar notebook kan de HTML in de output cell weergeven.  \n",
    "Het kan handig zijn om te zien wat de gekregen HTML representeerd.  \n",
    "De HTML is zonder CSS opmaak dus kan er anders uit zien dan in de browser.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "628bd3cf-1ff4-493f-b69f-a6021a732ac2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html><head><title>Computers database</title><link href=\"/assets/css/bootstrap.min.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/><link href=\"/assets/css/main.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/></head><body><header class=\"topbar\"><h1 class=\"fill\"><a class=\"fill\" href=\"/computers\">Computer database</a></h1></header><section id=\"main\"><h1>574 computers found</h1><div id=\"actions\"><form action=\"/computers\" method=\"GET\"><input id=\"searchbox\" name=\"f\" placeholder=\"Filter by computer name...\" required=\"required\" type=\"search\" value=\"\"/> <input class=\"btn primary\" id=\"searchsubmit\" type=\"submit\" value=\"Filter by name\"/><a class=\"btn success\" href=\"/computers/new\" id=\"add\">Add a new computer</a></form></div><table class=\"computers zebra-striped\"><thead><th class=\"col-name header headerSortUp\"><a href=\"/computers?p=0&amp;n=5&amp;s=name&amp;d=desc\">Computer name</a></th><th class=\"col-introduced header\"><a href=\"/computers?p=0&amp;n=5&amp;s=introduced&amp;d=asc\">Introduced</a></th><th class=\"col-discontinued header\"><a href=\"/computers?p=0&amp;n=5&amp;s=discontinued&amp;d=asc\">Discontinued</a></th><th class=\"col-company header\"><a href=\"/computers?p=0&amp;n=5&amp;s=companyName&amp;d=asc\">Company</a></th></thead><tbody><tr><td><a href=\"/computers/381\">ACE</a></td><td>-</td><td>-</td><td>-</td></tr><tr><td><a href=\"/computers/501\">AN/FSQ-32</a></td><td>01 Jan 1960</td><td>-</td><td>IBM</td></tr><tr><td><a href=\"/computers/500\">AN/FSQ-7</a></td><td>01 Jan 1958</td><td>-</td><td>IBM</td></tr><tr><td><a href=\"/computers/388\">APEXC</a></td><td>-</td><td>-</td><td>-</td></tr><tr><td><a href=\"/computers/355\">ARRA</a></td><td>-</td><td>-</td><td>-</td></tr></tbody></table><div class=\"pagination\" id=\"pagination\"><ul><li class=\"prev disabled\"><a>← Previous</a></li><li class=\"current\"><a>Displaying 1 to 5 of 574</a></li><li class=\"next\"><a href=\"/computers?p=1&amp;n=5&amp;s=name&amp;d=asc\">Next →</a></li></ul></div></section></body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optioneel\n",
    "from IPython import display\n",
    "display.HTML(str(soup))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d2c1a2-3ac6-497d-b280-456da6b9a516",
   "metadata": {},
   "source": [
    "De data in de table van de HTML is nodig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a2ab8da-1d1d-4752-8e3f-a317b40dd55b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"computers zebra-striped\"><thead><th class=\"col-name header headerSortUp\"><a href=\"/computers?p=0&amp;n=5&amp;s=name&amp;d=desc\">Computer name</a></th><th class=\"col-introduced header\"><a href=\"/computers?p=0&amp;n=5&amp;s=introduced&amp;d=asc\">Introduced</a></th><th class=\"col-discontinued header\"><a href=\"/computers?p=0&amp;n=5&amp;s=discontinued&amp;d=asc\">Discontinued</a></th><th class=\"col-company header\"><a href=\"/computers?p=0&amp;n=5&amp;s=companyName&amp;d=asc\">Company</a></th></thead><tbody><tr><td><a href=\"/computers/381\">ACE</a></td><td>-</td><td>-</td><td>-</td></tr><tr><td><a href=\"/computers/501\">AN/FSQ-32</a></td><td>01 Jan 1960</td><td>-</td><td>IBM</td></tr><tr><td><a href=\"/computers/500\">AN/FSQ-7</a></td><td>01 Jan 1958</td><td>-</td><td>IBM</td></tr><tr><td><a href=\"/computers/388\">APEXC</a></td><td>-</td><td>-</td><td>-</td></tr><tr><td><a href=\"/computers/355\">ARRA</a></td><td>-</td><td>-</td><td>-</td></tr></tbody></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = soup.table\n",
    "display.HTML(str(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8f3e07-ed96-41ff-9973-1694629378a7",
   "metadata": {},
   "source": [
    "Met een [list-comprehension] kan er  over de `<th>` tags geitereerd worden en zo uit elke tag de text filteren.  \n",
    "Een list-comprehension is een loop in een data container zoals een `list`.  \n",
    "De loop itereert en plaatst te objecten in een nieuwe data-container.  \n",
    "list-comprehensions zijn efficient en flexibel.\n",
    "\n",
    "[list-comprehension]: https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25bdcdf1-8007-429d-a4ba-25ce8bb6119d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Computer name', 'Introduced', 'Discontinued', 'Company']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = [h.get_text() for h in table.thead.find_all('th')]\n",
    "headers  # list met str objecten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0782e56-afdb-456b-bdbe-8a6ad24c280d",
   "metadata": {},
   "source": [
    "Nu er een lijst met headers is is er een indicatie welke cel wat bevat.  \n",
    "De headers kan gebruikt worden als _key_ in een dict.  \n",
    "De cellen in de regels zijn dan de _values_.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dba29eb7-4fce-4c33-b6f8-be67b0f63fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tr><td><a href=\"/computers/381\">ACE</a></td><td>-</td><td>-</td><td>-</td></tr>,\n",
       " <tr><td><a href=\"/computers/501\">AN/FSQ-32</a></td><td>01 Jan 1960</td><td>-</td><td>IBM</td></tr>,\n",
       " <tr><td><a href=\"/computers/500\">AN/FSQ-7</a></td><td>01 Jan 1958</td><td>-</td><td>IBM</td></tr>,\n",
       " <tr><td><a href=\"/computers/388\">APEXC</a></td><td>-</td><td>-</td><td>-</td></tr>,\n",
       " <tr><td><a href=\"/computers/355\">ARRA</a></td><td>-</td><td>-</td><td>-</td></tr>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = table.tbody.find_all('tr')\n",
    "rows  # list met bs4.element.Tag objecten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367a0ad1-462e-4a25-b549-a25af97462cc",
   "metadata": {},
   "source": [
    "De headers en zijn de regels geparsed uit de table van de website.  \n",
    "Nu kan deze data in een CSV file of JSON gezet worden.\n",
    "\n",
    "Hieronder een voorbeeld hoe er een JSON van de data gemaakt kan worden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b48e0cbe-0941-45ee-a607-1905f3e3ecf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"rows\": [\n",
      "    {\n",
      "      \"Computer name\": \"ACE\",\n",
      "      \"Introduced\": \"-\",\n",
      "      \"Discontinued\": \"-\",\n",
      "      \"Company\": \"-\"\n",
      "    },\n",
      "    {\n",
      "      \"Computer name\": \"AN/FSQ-32\",\n",
      "      \"Introduced\": \"01 Jan 1960\",\n",
      "      \"Discontinued\": \"-\",\n",
      "      \"Company\": \"IBM\"\n",
      "    },\n",
      "    {\n",
      "      \"Computer name\": \"AN/FSQ-7\",\n",
      "      \"Introduced\": \"01 Jan 1958\",\n",
      "      \"Discontinued\": \"-\",\n",
      "      \"Company\": \"IBM\"\n",
      "    },\n",
      "    {\n",
      "      \"Computer name\": \"APEXC\",\n",
      "      \"Introduced\": \"-\",\n",
      "      \"Discontinued\": \"-\",\n",
      "      \"Company\": \"-\"\n",
      "    },\n",
      "    {\n",
      "      \"Computer name\": \"ARRA\",\n",
      "      \"Introduced\": \"-\",\n",
      "      \"Discontinued\": \"-\",\n",
      "      \"Company\": \"-\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "row_list = []\n",
    "\n",
    "for row in rows:\n",
    "    row_text = [r.get_text() for r in row]  # list comprehension om een list met text te maken\n",
    "    # dict-zip\n",
    "    header_row_dict = dict(zip(headers, row_text))\n",
    "    row_list.append(header_row_dict)\n",
    "\n",
    "\n",
    "# creeer de json\n",
    "created_json = json.dumps({'rows': row_list}, indent=2)\n",
    "print(created_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68546376-cd20-4e80-853f-1a8bec56d342",
   "metadata": {},
   "source": [
    "Hieronder een voorbeeld hoe de er een CSV file met de data gemaakt kan worden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "deec48c0-8858-4e92-a554-79a8cadedd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computer name,Introduced,Discontinued,Company\n",
      "ACE,-,-,-\n",
      "AN/FSQ-32,01 Jan 1960,-,IBM\n",
      "AN/FSQ-7,01 Jan 1958,-,IBM\n",
      "APEXC,-,-,-\n",
      "ARRA,-,-,-\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# csv filename\n",
    "filename = 'gatling_io.csv'\n",
    "\n",
    "# `with` context manager\n",
    "with open(filename, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    \n",
    "    writer.writerow(headers)  # schrijf de header regel (fieldnames)\n",
    "    for row in rows:\n",
    "        row_text = [r.get_text() for r in row]\n",
    "        writer.writerow(row_text)  # schrijf de regels\n",
    "\n",
    "\n",
    "# open en lees de gemaakte file.\n",
    "for line in open(filename, 'r').readlines():\n",
    "    print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604f6ce0-ac24-4032-a830-1651a044edfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
