{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfe6ed68-eca1-46d7-9665-3a5f86f5d3a5",
   "metadata": {},
   "source": [
    "# Webscraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28892af-56c3-44a1-8cf0-251af2439acb",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "Dit notebook laat manieren zien hoe webpaginas te manipuleren zijn en hoe de data ervan te _scrapen_ is. \n",
    "\n",
    "> \"_Scrapen is een computertechniek waarbij software wordt gebruikt om informatie van webpagina's te extraheren en al dan niet te analyseren._\"  <sub>[wiki]<sub>\n",
    "\n",
    "\n",
    "Python heeft een aantal [internet] tools die daarbij helpen.  \n",
    "De meest gebruike zijn [urllib.request] en [html.parser].  \n",
    "Deze libraries hebben een _low-level_ design waardoor het te customizen is.  \n",
    "Hierdoor moet er een hoop code schrijven om de functies zo te maken dat het doel wordt bereikt.  \n",
    "Gelukkig zijn er third-party libraries die een _high-level_ interface bieden.  \n",
    "Python heeft ook de [json] module om objecten te encoden naar json en inkomende json te decoden.  \n",
    "\n",
    "Er zijn veel Third-party libraries de gebruikt kunnen worden om data van het web te halen.  \n",
    "Hieronder een kleine selectie waarvan we een paar in dit notebook gaat gebruiken.  \n",
    "\n",
    "[requests] is de _high-level_ interface om [HTTP request methods] te versturen naar API's of websites.\n",
    "\n",
    "[beautifulsoup4] wordt gebruikt om HTML of XML te parsen.  \n",
    "\n",
    "[selenium], de meest bekende web-automation tool welk ook veel gebruikt wordt om websites te testen.  \n",
    "\n",
    "[scrapy] een web-crawler framework voor Python met een hoop features.\n",
    "\n",
    "[httpx] de _next-generation_ HTTP client voor Python.  \n",
    "Als je bekend ben met [requests] dan is de overstap naar [httpx] klein.  \n",
    "Ondersteunt HTTP2 en de Python [async] functionaliteit waar [requests] dit niet ondersteunt.\n",
    "\n",
    "---\n",
    "    \n",
    "Naast Python gaan we ook werken met de [Developer tools] van de web browser.  \n",
    "[Chrome] en [Firefox] hebben dat beiden in hun browser.  \n",
    "De knop `F12` of de sneltoetsen `Shift` + `Control` + `I` opent de developer tools van de browser.  \n",
    "    \n",
    "[internet]: https://docs.python.org/3/library/internet.html \"Internet Protocols and Support\"\n",
    "[urllib.request]: https://docs.python.org/3/library/urllib.request.html \"Extensible library for opening URLs\"\n",
    "[json]: https://docs.python.org/3/library/json.html \"JSON encoder and decoder\"\n",
    "[html.parser]: https://docs.python.org/3/library/html.parser.html \"Simple HTML and XHTML parser\"\n",
    "\n",
    "[httpx]: https://www.python-httpx.org/ \"A next-generation HTTP client for Python\"\n",
    "[scrapy]: https://scrapy.org/ \"Web Crawling Framework\"\n",
    "[selenium]: https://www.selenium.dev/documentation/en/ \"selenium\"\n",
    "[beautifulsoup4]: https://beautiful-soup-4.readthedocs.io/en/latest/ \"Beautiful Soup\"\n",
    "[requests]: https://docs.python-requests.org/en/master/index.html \"Requests: HTTP for Humans\"\n",
    "\n",
    "[wiki]: https://nl.wikipedia.org/wiki/Scrapen\n",
    "[HTTP request methods]: https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods \"HTTP request methods\"\n",
    "[async]: https://docs.python.org/3/library/asyncio.html\n",
    "\n",
    "[Developer tools]: https://en.wikipedia.org/wiki/Web_development_tools\n",
    "[Chrome]: https://developer.chrome.com/docs/devtools/open/ \"Chrome Developer tools\"\n",
    "[Firefox]: https://developer.mozilla.org/en-US/docs/Learn/Common_questions/What_are_browser_developer_tools \"Firefox Developer tools\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac54e4a9-6616-4816-b579-28d1c0b3d9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/username/Documents/Scripts/jupyter_lab_venv/lib/python3.9/site-packages (21.2.4)\n",
      "Requirement already satisfied: requests in /home/username/Documents/Scripts/jupyter_lab_venv/lib/python3.9/site-packages (2.26.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/username/Documents/Scripts/jupyter_lab_venv/lib/python3.9/site-packages (4.10.0)\n",
      "Requirement already satisfied: selenium in /home/username/Documents/Scripts/jupyter_lab_venv/lib/python3.9/site-packages (3.141.0)\n",
      "Requirement already satisfied: webdriver-manager in /home/username/Documents/Scripts/jupyter_lab_venv/lib/python3.9/site-packages (3.4.2)\n",
      "Requirement already satisfied: openpyxl in /home/username/Documents/Scripts/jupyter_lab_venv/lib/python3.9/site-packages (3.0.7)\n",
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.0.8-py2.py3-none-any.whl (244 kB)\n",
      "\u001b[K     |████████████████████████████████| 244 kB 3.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /home/username/Documents/Scripts/jupyter_lab_venv/lib/python3.9/site-packages (from requests) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/username/Documents/Scripts/jupyter_lab_venv/lib/python3.9/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/username/Documents/Scripts/jupyter_lab_venv/lib/python3.9/site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/username/Documents/Scripts/jupyter_lab_venv/lib/python3.9/site-packages (from requests) (1.26.6)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/username/Documents/Scripts/jupyter_lab_venv/lib/python3.9/site-packages (from beautifulsoup4) (2.2.1)\n",
      "Requirement already satisfied: configparser in /home/username/Documents/Scripts/jupyter_lab_venv/lib/python3.9/site-packages (from webdriver-manager) (5.0.2)\n",
      "Requirement already satisfied: crayons in /home/username/Documents/Scripts/jupyter_lab_venv/lib/python3.9/site-packages (from webdriver-manager) (0.4.0)\n",
      "Requirement already satisfied: et-xmlfile in /home/username/Documents/Scripts/jupyter_lab_venv/lib/python3.9/site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: colorama in /home/username/Documents/Scripts/jupyter_lab_venv/lib/python3.9/site-packages (from crayons->webdriver-manager) (0.4.4)\n",
      "Installing collected packages: openpyxl\n",
      "  Attempting uninstall: openpyxl\n",
      "    Found existing installation: openpyxl 3.0.7\n",
      "    Uninstalling openpyxl-3.0.7:\n",
      "      Successfully uninstalled openpyxl-3.0.7\n",
      "Successfully installed openpyxl-3.0.8\n"
     ]
    }
   ],
   "source": [
    "# install the packages\n",
    "!python -m pip install --upgrade pip requests beautifulsoup4 selenium webdriver-manager openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f019bce-e422-4e50-bd65-a7c3384a520d",
   "metadata": {},
   "source": [
    "## Scrapen met een API\n",
    "\n",
    "Het makelijkste om data op te vragen is doormiddel van een API.  \n",
    "Veel van de meeste websites hebben geen openbare API.  \n",
    "Toch kan het zo zijn dat de website een API gebruikt om data van de client naar de server te sturen.  \n",
    "Zo kan de website dynamisch _(zonder te refreshen)_ de data op de pagina updaten.   \n",
    "Hiervoor wordt [XMLHTTPRequests (XHR)] gebruikt.\n",
    "\n",
    "In de Developer Tools onder de tab Network zie je het dataverkeer en de daarbij horende HTTP request methods.  \n",
    "Om goed te zien wat een website krijgt en verstuurd moet de optie Preserve log/ Persist Logs en de Disable Cache aan staan.  \n",
    "Met deze opties aan behoudt de network tab alle logs en vraagt de website alle data op die anders werd onthouden in de Cache.  \n",
    "\n",
    "---\n",
    "\n",
    "https://www.demoblaze.com/ een demo website van [Blazemeter] en gebruikt XHR.  \n",
    "In de notebook cells hieronder open we de demo website en bekijken we de Network tab voor XHR berichtenverkeer.  \n",
    "En gaan we [requests] gebruiken om data van de webpagina op te vragen.  \n",
    "\n",
    "[XMLHTTPRequests (XHR)]: https://nl.wikipedia.org/wiki/XMLHTTP\n",
    "[Blazemeter]: https://www.blazemeter.com/\n",
    "[requests]: https://docs.python-requests.org/en/master/index.html \"Requests: HTTP for Humans\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacc5291-7deb-4e48-8e88-4bc8388367b2",
   "metadata": {},
   "source": [
    "Open een browser en de developer tools.  \n",
    "Zet de opties Preserve logs, Disable cache aan en filter op XHR  \n",
    "\n",
    "> ![Developer tools](./img/devtools_XHR_filter.png \"Preserve logs, Disable cache, filter XHR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb0abcb-487a-4914-bbde-0540aabeafb6",
   "metadata": {},
   "source": [
    "Als er dan de demo website wordt geopend zien we dat er wat XHR type requests gedaan wordt.  \n",
    "De url https://www.demoblaze.com/config.json wordt opgevraagt met de GET method.  \n",
    "\n",
    "> ![Developer tools XHR get](./img/devtools_XHR_get_request.png \"GET request, XHR type response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6de7a1b-d3d1-4e76-a998-e400f3b2ba64",
   "metadata": {},
   "source": [
    "Als we er op klikken zien we de data die verstuurd en terug gekregen is.  \n",
    "Onder de tab Response krijgen we de _Raw response data_ te zien.  \n",
    "Dit kan van alles zijn, HTML, javascript en in dit geval JSON.  \n",
    "\n",
    "> ![Developer tools XHR response](./img/devtools_XHR_response.png \"raw response\")\n",
    "\n",
    "Hieronder wordt Python requests gebruikt om dezelfde data op te vragen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ac932df-180f-4cae-8177-8a24e1e465aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "base_url = 'https://www.demoblaze.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5fab87d-9910-4732-9fcd-ce01231c61b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\\n    \"API_URL\": \"https://api.demoblaze.com\",\\n    \"HLS_URL\": \"https://hls.demoblaze.com\"\\n}'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'config.json'\n",
    "url = urljoin(base_url, path)\n",
    "res = requests.get(url)\n",
    "\n",
    "# response content is de data terug gekregen van de GET request (Raw response data)\n",
    "res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e255cddb-43e3-4da4-96cc-9db229d0df74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'API_URL': 'https://api.demoblaze.com',\n",
       " 'HLS_URL': 'https://hls.demoblaze.com'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HLS is een streaming protocol\n",
    "# de API_URL hebben is nodig\n",
    "\n",
    "# er is JSON data ontvangen\n",
    "# de data kan geparsed worden door Python json module of door de Response.json() functie naar een dict.\n",
    "config_dict = res.json()\n",
    "config_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f388857-8142-4666-8f8b-d6be8fff7377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://api.demoblaze.com'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_url = config_dict.get('API_URL')\n",
    "api_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14ed447-5769-4766-b06b-b6ed4805a3e3",
   "metadata": {},
   "source": [
    "Op de demo website is er een lijst te zien met product catagories.  \n",
    "Wordt er op de Laptop catagorie geklikt dan wordt de Laptop catagorie opgrvraag van de server.  \n",
    "Dit gebeurt met een POST request naar de API url met het _bycat_ path.  \n",
    "Een POST request bevat meestal een payload of speciale headers, in dit geval is de payload een JSON string.  \n",
    "\n",
    "> ![Catagory request met payload](./img/devtools_post_request.png \"POST request met JSON payload\")\n",
    "\n",
    "In de tab Response zien we de data die verkregen is van de server.  \n",
    "Dit is wederom JSON data. \n",
    "\n",
    "Hieronder wordt Python requests gebruikt om dezelfde data op te vragen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dfc9a1d-5719-40bc-bff5-d07180263308",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'bycat'\n",
    "url = urljoin(api_url, path)\n",
    "\n",
    "payload = {'cat': 'notebook'}\n",
    "\n",
    "res = requests.post(url, json=payload)\n",
    "notebook_dict =  res.json()\n",
    "# dict structure: {'Items': [{'cat': 'notebook', id: <int>, 'img': <str>, 'price': <float>, 'title', <str>}, ... ]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87751a8e-a82e-485d-845c-d1005b9f81db",
   "metadata": {},
   "source": [
    "Nu de data is verkregen kan er overheen worden geitereerd.  \n",
    "De data kunnen we dan opslaan in een database, csv of Excel bestand.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51db0047-dfaa-468c-9b28-7c8b87956a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sony vaio i5         €790.0\n",
      "Sony vaio i7         €790.0\n",
      "MacBook air          €700.0\n",
      "Dell i7 8gb          €700.0\n",
      "2017 Dell 15.6 Inch  €700.0\n",
      "MacBook Pro          €1100.0\n"
     ]
    }
   ],
   "source": [
    "# loop over de items in de dict\n",
    "for item in notebook_dict['Items']:\n",
    "    if not item.get('cat') == 'notebook':  # skip de items die geen notebook zijn.\n",
    "        continue\n",
    "    title = item.get('title').strip()  # strip de whitespaces en newlines van de string.\n",
    "    price = item.get('price')\n",
    "    print(f'{title:20} €{price}')  # maak 'title' minstens 20 characters breed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648ca13a-ca6c-4f63-8d8a-431cfd2f62e4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Scrapen door de HTML te parsen\n",
    "\n",
    "HTML (HyperTextMarkupLanguage) is de opmaak van een webpagina.  \n",
    "De HTML kan dynamisch worden opgemaakt met (bijvoorbeeld) Javascipt code.  \n",
    "Maar HTML paginas kunnen ook statisch zijn.  \n",
    "Een statische pagina moet ververst worden om nieuwe data te zien.\n",
    "\n",
    "De server die de paginas naar de client stuurt moet wel weten wat het moet doen browser (client) een pagina opvraagt.  \n",
    "Als dit niet via JSON of speciale headers gebeurd dan wordt het commando beschreven in de URL zelf.  \n",
    "Dit gebeurd doormiddel van een _query_.  \n",
    "\n",
    "Een _query_ is de gedeelte in een URL na de `?`.  \n",
    "de query bestaat uit een _key_ en optioneel een _value_.  \n",
    "key en value worden aan elkaar gekoppeld doormiddel van een `=`.  \n",
    "Er kunnen ook meerdere queries in een url als de queries gesepereerd worden door een `&`.  \n",
    "De keys en values hoeven niet uniek te zijn.\n",
    "\n",
    "Voorbeeld van een valide URL:  \n",
    "`https://www.web.site/path.html?key=value&key=value&only_key`\n",
    "\n",
    "---\n",
    "\n",
    "https://computer-database.gatling.io/computers is een statische demo website van [Gatling] en gebruikt parameters in de URL.  \n",
    "In de notebook cells hieronder open we de demo website en bekijken we de Network tab voor XHR berichtenverkeer.  \n",
    "En gaan we [requests] gebruiken om data van de webpagina op te vragen.  \n",
    "We parsen de HTML met [beautifulsoup4].  \n",
    "\n",
    "[Gatling]: https://gatling.io\n",
    "[requests]: https://docs.python-requests.org/en/master/index.html \"Requests: HTTP for Humans\"\n",
    "[beautifulsoup4]: https://beautiful-soup-4.readthedocs.io/en/latest/ \"Beautiful Soup\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9e214e-c098-406d-9bf8-2bf106198c72",
   "metadata": {},
   "source": [
    "Open een browser en navigeer naar de demo pagina.  \n",
    "Open de developer tools.  \n",
    "Klik op de next knop op de demo pagina.\n",
    "In de developer tools open kan er worden gezien dat er een GET request is geweest.  \n",
    "De request en de URL in de browser hebben een query.  \n",
    "\n",
    "> ![query string params](./img/devtools_query_params.png \"Query String Parameters\")\n",
    "\n",
    "Met wat giswerk kan er worden bedacht wat de query bevat.\n",
    "\n",
    "`p=0` de key `p` en de value als cijfer moet waarschijnlijk de pagina voorstellen.  \n",
    "`n=10` de key `n` is hoogstwaarschijnlijk het aantal items in de [table] op de pagina.  \n",
    "`s=name` de [table] is gesorteerd op naam, dus `s` is voor _sort_.  \n",
    "`d=asc` moet dan voor de manier van sorteren zijn, `asc` staat voor _ascending_.\n",
    "\n",
    "[table]: https://developer.mozilla.org/en-US/docs/Learn/HTML/Tables/Basics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045e4abe-4eb6-47cb-bbb8-60336d63c8dd",
   "metadata": {},
   "source": [
    "Met deze kennis kunnen we een query maken voor een tabel met de benodigde regels.  \n",
    "De URL + query kan dan met Python-requests worden opgevraagd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d663bcf-84d5-4879-a89c-16697a8544ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urljoin\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab33f2c6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://computer-database.gatling.io/computers?p=0&n=5'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = 'https://computer-database.gatling.io/computers'\n",
    "query = '?p={page}&n={rows}'\n",
    "url = urljoin(base_url, query.format(page=0, rows=5))  # pagina 0, regels 5\n",
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dafc135-b64f-4137-8459-0f68e6259186",
   "metadata": {},
   "source": [
    "De URL is gecreeerd en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb4d4f4f-c8c2-42b0-a46b-39a3007e1a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86fbf20-2b29-451a-a917-430912e2d5fd",
   "metadata": {},
   "source": [
    "Het is niet nodig maar notebook kan de HTML in de output cell weergeven.  \n",
    "Het kan handig zijn om te zien wat de gekregen HTML representeerd.  \n",
    "De HTML is zonder CSS opmaak dus kan er anders uit zien dan in de browser.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "628bd3cf-1ff4-493f-b69f-a6021a732ac2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html><head><title>Computers database</title><link href=\"/assets/css/bootstrap.min.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/><link href=\"/assets/css/main.css\" media=\"screen\" rel=\"stylesheet\" type=\"text/css\"/></head><body><header class=\"topbar\"><h1 class=\"fill\"><a class=\"fill\" href=\"/computers\">Computer database</a></h1></header><section id=\"main\"><h1>574 computers found</h1><div id=\"actions\"><form action=\"/computers\" method=\"GET\"><input id=\"searchbox\" name=\"f\" placeholder=\"Filter by computer name...\" required=\"required\" type=\"search\" value=\"\"/> <input class=\"btn primary\" id=\"searchsubmit\" type=\"submit\" value=\"Filter by name\"/><a class=\"btn success\" href=\"/computers/new\" id=\"add\">Add a new computer</a></form></div><table class=\"computers zebra-striped\"><thead><th class=\"col-name header headerSortUp\"><a href=\"/computers?p=0&amp;n=5&amp;s=name&amp;d=desc\">Computer name</a></th><th class=\"col-introduced header\"><a href=\"/computers?p=0&amp;n=5&amp;s=introduced&amp;d=asc\">Introduced</a></th><th class=\"col-discontinued header\"><a href=\"/computers?p=0&amp;n=5&amp;s=discontinued&amp;d=asc\">Discontinued</a></th><th class=\"col-company header\"><a href=\"/computers?p=0&amp;n=5&amp;s=companyName&amp;d=asc\">Company</a></th></thead><tbody><tr><td><a href=\"/computers/381\">ACE</a></td><td>-</td><td>-</td><td>-</td></tr><tr><td><a href=\"/computers/501\">AN/FSQ-32</a></td><td>01 Jan 1960</td><td>-</td><td>IBM</td></tr><tr><td><a href=\"/computers/500\">AN/FSQ-7</a></td><td>01 Jan 1958</td><td>-</td><td>IBM</td></tr><tr><td><a href=\"/computers/388\">APEXC</a></td><td>-</td><td>-</td><td>-</td></tr><tr><td><a href=\"/computers/355\">ARRA</a></td><td>-</td><td>-</td><td>-</td></tr></tbody></table><div class=\"pagination\" id=\"pagination\"><ul><li class=\"prev disabled\"><a>← Previous</a></li><li class=\"current\"><a>Displaying 1 to 5 of 574</a></li><li class=\"next\"><a href=\"/computers?p=1&amp;n=5&amp;s=name&amp;d=asc\">Next →</a></li></ul></div></section></body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optioneel\n",
    "from IPython import display\n",
    "display.HTML(str(soup))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d2c1a2-3ac6-497d-b280-456da6b9a516",
   "metadata": {},
   "source": [
    "De data in de table van de HTML is nodig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a2ab8da-1d1d-4752-8e3f-a317b40dd55b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"computers zebra-striped\"><thead><th class=\"col-name header headerSortUp\"><a href=\"/computers?p=0&amp;n=5&amp;s=name&amp;d=desc\">Computer name</a></th><th class=\"col-introduced header\"><a href=\"/computers?p=0&amp;n=5&amp;s=introduced&amp;d=asc\">Introduced</a></th><th class=\"col-discontinued header\"><a href=\"/computers?p=0&amp;n=5&amp;s=discontinued&amp;d=asc\">Discontinued</a></th><th class=\"col-company header\"><a href=\"/computers?p=0&amp;n=5&amp;s=companyName&amp;d=asc\">Company</a></th></thead><tbody><tr><td><a href=\"/computers/381\">ACE</a></td><td>-</td><td>-</td><td>-</td></tr><tr><td><a href=\"/computers/501\">AN/FSQ-32</a></td><td>01 Jan 1960</td><td>-</td><td>IBM</td></tr><tr><td><a href=\"/computers/500\">AN/FSQ-7</a></td><td>01 Jan 1958</td><td>-</td><td>IBM</td></tr><tr><td><a href=\"/computers/388\">APEXC</a></td><td>-</td><td>-</td><td>-</td></tr><tr><td><a href=\"/computers/355\">ARRA</a></td><td>-</td><td>-</td><td>-</td></tr></tbody></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = soup.table\n",
    "display.HTML(str(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8f3e07-ed96-41ff-9973-1694629378a7",
   "metadata": {},
   "source": [
    "Met een [list-comprehension] kan er  over de `<th>` tags geitereerd worden en zo uit elke tag de text filteren.  \n",
    "Een list-comprehension is een loop in een data container zoals een `list`.  \n",
    "De loop itereert en plaatst te objecten in een nieuwe data-container.  \n",
    "list-comprehensions zijn efficient en flexibel.\n",
    "\n",
    "[list-comprehension]: https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25bdcdf1-8007-429d-a4ba-25ce8bb6119d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Computer name', 'Introduced', 'Discontinued', 'Company']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = [h.get_text() for h in table.thead.find_all('th')]\n",
    "headers  # list met str objecten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0782e56-afdb-456b-bdbe-8a6ad24c280d",
   "metadata": {},
   "source": [
    "Nu er een lijst met headers is is er een indicatie welke cel wat bevat.  \n",
    "De headers kan gebruikt worden als _key_ in een dict.  \n",
    "De cellen in de regels zijn dan de _values_.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dba29eb7-4fce-4c33-b6f8-be67b0f63fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tr><td><a href=\"/computers/381\">ACE</a></td><td>-</td><td>-</td><td>-</td></tr>,\n",
       " <tr><td><a href=\"/computers/501\">AN/FSQ-32</a></td><td>01 Jan 1960</td><td>-</td><td>IBM</td></tr>,\n",
       " <tr><td><a href=\"/computers/500\">AN/FSQ-7</a></td><td>01 Jan 1958</td><td>-</td><td>IBM</td></tr>,\n",
       " <tr><td><a href=\"/computers/388\">APEXC</a></td><td>-</td><td>-</td><td>-</td></tr>,\n",
       " <tr><td><a href=\"/computers/355\">ARRA</a></td><td>-</td><td>-</td><td>-</td></tr>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = table.tbody.find_all('tr')\n",
    "rows  # list met bs4.element.Tag objecten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367a0ad1-462e-4a25-b549-a25af97462cc",
   "metadata": {},
   "source": [
    "De headers en zijn de regels geparsed uit de table van de website.  \n",
    "Nu kan deze data in een CSV file of JSON gezet worden.\n",
    "\n",
    "Hieronder een voorbeeld hoe er een JSON van de data gemaakt kan worden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b48e0cbe-0941-45ee-a607-1905f3e3ecf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"rows\": [{\"Computer name\": \"ACE\", \"Introduced\": \"-\", \"Discontinued\": \"-\", \"Company\": \"-\"}, {\"Computer name\": \"AN/FSQ-32\", \"Introduced\": \"01 Jan 1960\", \"Discontinued\": \"-\", \"Company\": \"IBM\"}, {\"Computer name\": \"AN/FSQ-7\", \"Introduced\": \"01 Jan 1958\", \"Discontinued\": \"-\", \"Company\": \"IBM\"}, {\"Computer name\": \"APEXC\", \"Introduced\": \"-\", \"Discontinued\": \"-\", \"Company\": \"-\"}, {\"Computer name\": \"ARRA\", \"Introduced\": \"-\", \"Discontinued\": \"-\", \"Company\": \"-\"}]}'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "row_list = []\n",
    "\n",
    "for row in rows:\n",
    "    row_text = [r.get_text() for r in row]  # list comprehension om een list met text te maken\n",
    "    # dict-zip\n",
    "    header_row_dict = dict(zip(headers, row_text))\n",
    "    row_list.append(header_row_dict)\n",
    "\n",
    "\n",
    "# creeer de json\n",
    "json.dumps({'rows': row_list})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68546376-cd20-4e80-853f-1a8bec56d342",
   "metadata": {},
   "source": [
    "Hieronder een voorbeeld hoe de er een CSV file met de data gemaakt kan worden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "deec48c0-8858-4e92-a554-79a8cadedd22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Computer name,Introduced,Discontinued,Company\\nACE,-,-,-\\nAN/FSQ-32,01 Jan 1960,-,IBM\\nAN/FSQ-7,01 Jan 1958,-,IBM\\nAPEXC,-,-,-\\nARRA,-,-,-\\n'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "filename = 'gatling_io.txt'\n",
    "\n",
    "# `with` context manager\n",
    "with open(filename, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    \n",
    "    writer.writerow(headers)  # schrijf de header regel (fieldnames)\n",
    "    for row in rows:\n",
    "        row_text = [r.get_text() for r in row]\n",
    "        writer.writerow(row_text)  # schrijf de regels\n",
    "\n",
    "\n",
    "# open en lees de gemaakte file.\n",
    "open(filename, 'r').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60e1aa2-f8d8-4222-bce0-dc25e56dfff3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Scrapen van een website met Selenium\n",
    "\n",
    "Scrapen met [Selenium] is niet de meest betrouwbare manier van webscraping.  \n",
    "Maar sommige websites hebben (veel) Javascript of [iframe] HTML tags of laden dynamisch nieuwe elementen waardoor de data moeilijk te scrapen is met andere technieken.  \n",
    "Het is dan toch mogenlijk om de website te scrapen met Selenium.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "https://sroze.github.io/ngInfiniteScroll/demo_async.html is een demo website voor een [infinite scroll] Javascript module die werkt met het webapplicatieframework [AngularJS].  \n",
    "De website gebruikt de [Reddit API] om tot en met 1000 artikelen te laden als de einde van de pagina wordt bereikt.  \n",
    "In de notebook cells hieronder open we de demo website en gebruiken we Selenium (met een beetje Javascript) om te scrollen.\n",
    "De artikelen parsen \n",
    "\n",
    "\n",
    "\n",
    "[iframe]: https://www.w3docs.com/learn-html/html-iframe-tag.html\n",
    "[Selenium]: https://pypi.org/project/selenium/\n",
    "[webdriver_manager]: https://pypi.org/project/webdriver-manager/ \n",
    "\n",
    "[infinite scroll]: https://github.com/sroze/ngInfiniteScroll\n",
    "[AngularJS]: https://angularjs.org/\n",
    "\n",
    "[Reddit API]: https://www.reddit.com/dev/api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b17ef40-baff-47c2-8e15-502d97b177af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current chromium version is 94.0.4606\n",
      "Get LATEST driver version for 94.0.4606\n",
      "There is no [linux64] chromedriver for browser 94.0.4606 in cache\n",
      "Get LATEST driver version for 94.0.4606\n",
      "Trying to download new driver from https://chromedriver.storage.googleapis.com/94.0.4606.41/chromedriver_linux64.zip\n",
      "Driver has been saved in cache [/home/username/.wdm/drivers/chromedriver/linux64/94.0.4606.41]\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.remote.webdriver import WebDriver\n",
    "from selenium.webdriver.remote.webelement import WebElement\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from webdriver_manager.utils import ChromeType\n",
    "\n",
    "# driver = webdriver.Chrome(ChromeDriverManager().install())  # chrome\n",
    "driver = webdriver.Chrome(ChromeDriverManager(chrome_type=ChromeType.CHROMIUM).install())  # chromium\n",
    "# driver = webdriver.Firefox(executable_path=GeckoDriverManager().install())  # firefox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86260497-ebfd-4510-b3ca-bb84e0fbe218",
   "metadata": {},
   "source": [
    "Er browser die geopend is bij het aanroepen van de `webdriver.Chrome`.   \n",
    "Deze browser wordt nu gecommandeerd door Python via het `driver` object.  \n",
    "\n",
    "Selenium heeft geen commando om de browser te scrollen maar Javascript wel.  \n",
    "Selenium kan javascript injecteren in de browser die gestart is door Selenium.\n",
    "\n",
    "Hieronder een functie die de viewport van de browser naar beneden laat scrollen.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61801221-32c0-4c9f-b5af-3e9882da247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_to_end(driver: WebDriver):\n",
    "    \"\"\"use javascript to scroll to the bottom of the website\"\"\"\n",
    "    code = 'window.scrollTo(0, document.body.scrollHeight)'\n",
    "    driver.execute_script(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6995c8-d460-4bb2-90ed-3cdca817d3db",
   "metadata": {},
   "source": [
    "Door een URL te geven aan het `get` functie van het `webdriver` object wordt er een webpagina geopend in de browser.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "476d167d-5079-482d-90c6-ef21a6da915b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://sroze.github.io/ngInfiniteScroll/demo_async.html'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bc6dda-30b9-4baa-a780-7ed88871f1e3",
   "metadata": {},
   "source": [
    "In de developer tools onder de tab Elements kan er een [XPath] worden gemaakt om een pad naar `WebElement` te maken.  \n",
    "De input om dit te doen wordt met de toetsencombinatie `Ctrl + F` geactiveerd. \n",
    "\n",
    "Met de functie `find_elements_by_xpath` _(elements meervoud)_ wordt alle webelementen opgevraagd die dat XPath hebben.\n",
    "\n",
    "[XPath]: https://nl.wikipedia.org/wiki/XPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef44bce9-8d4e-46b0-8fc1-fb82d5b40607",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"2bcd6b5ae50118c2320743f8378780d8\", element=\"52c39769-97d0-452b-8d48-493cf1c78a9b\")>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xpath_item = \"//div[@class='demo-container']/div[contains(@class, 'item')]\"\n",
    "items = driver.find_elements_by_xpath(xpath_item)\n",
    "items[0]  # check het eerste object in de lijst met WebElements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03957ac9-12c0-45b4-b139-418645eb5ad8",
   "metadata": {},
   "source": [
    "Hieronder is er een functie gemaakt die de `WebElement` als argument verwacht.  \n",
    "Met BeautifulSoup wordt dan de HTML geparsed om alle data te verkrijgen.  \n",
    "De data wordt opgevraagd, opgeschoond en direct in een `dict` geplaatst.  \n",
    "De `dict` met data wordt na het voltooien van de functie teruggegeven door de functie.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0688af7-1585-414a-bb90-c592e3a7bc93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data(item: WebElement) -> dict:\n",
    "    assert isinstance(item, WebElement), f'received type: {type(item)!r}'    \n",
    "    html = item.get_attribute('outerHTML')\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    result = {\n",
    "        'score': int(soup.find('span', {'class': 'score'}).text.strip()),  # string to int\n",
    "        'title': soup.find('span', {'class': 'title'}).text.strip(),\n",
    "        'url':   soup.find('a').get('href')\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3066529c-189c-4db1-b471-554000d959a5",
   "metadata": {},
   "source": [
    "Hieronder de geparste data van het eerste object in de lijst met WebElements.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b86731fa-8150-40ba-8d20-e3fa44be960e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 18945,\n",
       " 'title': 'What is the stupidest way you almost died?',\n",
       " 'url': 'https://www.reddit.com/r/AskReddit/comments/ptgt9j/what_is_the_stupidest_way_you_almost_died/'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data(items[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be687e6-410c-470a-ae2c-8d2836fcd128",
   "metadata": {},
   "source": [
    "Alle logica is gecreëerd om de browser te scrollen, data op te vragen en de data te parsen.  \n",
    "Om alle data op te vragen wordt hieronder een `while` loop gebruikt.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0bc3562-2f0b-4df0-bfd7-b72a25890e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = []\n",
    "while len(items) < 999:\n",
    "    items = driver.find_elements_by_xpath(xpath_item)\n",
    "    scroll_to_end(driver)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7cac95f-6148-4830-af54-5a77b317b270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(items)  # check hoe veel objecten de lijst items bevat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0284eb7-e8c8-410c-8b96-8aa754ec929b",
   "metadata": {},
   "source": [
    "Alle data is verkregen en nu kan hier wat mee worden gedaan.  \n",
    "Bijvoorbeeld kan het artikel met de hoogste score worden opgevraagd.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ec7050e-d258-4c3a-a6da-831f61bcf617",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 103407,\n",
       " 'title': 'The best come back ever',\n",
       " 'url': 'https://v.redd.it/jg0krsmkj4p71'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# een generator is een luie functie die data geeft waneer dit wordt opgevraagd.  \n",
    "item_generator = (get_data(item) for item in items)\n",
    "\n",
    "# verklaar objecten die gebruikt worden in de for-loop\n",
    "best_article = {}\n",
    "max_score = 0\n",
    "\n",
    "# loop om het artikel met de hoogste score te verkrijgen\n",
    "for data in item_generator:\n",
    "    score = data['score']\n",
    "    if max_score < score:\n",
    "        max_score = score\n",
    "        best_article = data\n",
    "\n",
    "best_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6de739-b278-4524-b58b-74ed275ab4c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
